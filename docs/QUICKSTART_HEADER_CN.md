# å¿«é€Ÿå¼€å§‹ï¼šç”¨æˆ·æŸ¥è¯¢ Header é…ç½®ï¼ˆä¸­æ–‡ç‰ˆï¼‰

## ğŸ’¡ æ ¸å¿ƒæ€è·¯

å½“ç”¨æˆ·é€šè¿‡ API æŸ¥è¯¢æ—¶ç”¨**é˜¿é‡Œäº‘ Qwen**ï¼ŒçŸ¥è¯†åº“æ„å»ºç­‰å†…éƒ¨æ“ä½œç”¨**æœ¬åœ° Qwen**ã€‚

å®ƒä»¬ä½¿ç”¨**åŒä¸€ä¸ªæœåŠ¡å™¨åœ°å€**ï¼Œä½†é€šè¿‡ **HTTP Header** åŒºåˆ†è¯·æ±‚ç±»å‹ã€‚

---

## âš¡ ä¸€åˆ†é’Ÿé…ç½®

### æ­¥éª¤ 1: ä¿®æ”¹ä½ çš„ LLM å‡½æ•°

åœ¨ç°æœ‰ LLM å‡½æ•°ä¸­æ·»åŠ ä¸€ä¸ªå‚æ•°å¤„ç†ï¼š

```python
async def your_llm_func(
    prompt, 
    system_prompt=None, 
    history_messages=[], 
    is_user_query=False,  # ğŸ‘ˆ æ–°å¢è¿™ä¸ªå‚æ•°
    **kwargs
):
    # è·å–å®¢æˆ·ç«¯é…ç½®
    client_configs = kwargs.pop("openai_client_configs", {})
    default_headers = client_configs.get("default_headers", {})
    
    # ğŸ‘‡ å…³é”®ä»£ç ï¼šæ ¹æ®è°ƒç”¨ç±»å‹æ·»åŠ ä¸åŒçš„ Header
    if is_user_query:
        default_headers["X-User-Query"] = "true"  # ç”¨æˆ·æŸ¥è¯¢
    else:
        default_headers["X-User-Query"] = "false"  # å†…éƒ¨è°ƒç”¨
    
    client_configs["default_headers"] = default_headers
    
    # è°ƒç”¨åŸæœ‰çš„ LLM æ¥å£ï¼ˆä¸ç”¨æ”¹å…¶ä»–ä»£ç ï¼‰
    return await openai_complete_if_cache(
        model=os.getenv("LLM_MODEL"),
        prompt=prompt,
        system_prompt=system_prompt,
        history_messages=history_messages,
        api_key=os.getenv("OPENAI_API_KEY"),
        base_url=os.getenv("LLM_BINDING_HOST"),  # åŒä¸€ä¸ªåœ°å€ï¼
        openai_client_configs=client_configs,    # ğŸ‘ˆ ä¼ å…¥é…ç½®
        **kwargs,
    )
```

### æ­¥éª¤ 2: å®Œæˆï¼

âœ… å°±è¿™ä¹ˆç®€å•ï¼å…¶ä»–ä»£ç **ä¸€è¡Œéƒ½ä¸ç”¨æ”¹**ï¼

---

## ğŸ”„ å·¥ä½œæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç”¨æˆ·æŸ¥è¯¢   â”‚ â†’ API (/query) â†’ is_user_query=True
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â†“
                         X-User-Query: true
                                 â†“
                         é˜¿é‡Œäº‘ Qwen æœåŠ¡å™¨

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ’å…¥æ–‡æ¡£    â”‚ â†’ å†…éƒ¨è°ƒç”¨ â†’ is_user_query=False
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â†“
                    X-User-Query: false
                            â†“
                    æœ¬åœ° Qwen æœåŠ¡å™¨
```

---

## ğŸ¯ è‡ªåŠ¨è¡Œä¸º

### âœ… ä»¥ä¸‹åœºæ™¯è‡ªåŠ¨è®¾ç½® `is_user_query=True`ï¼ˆç”¨æˆ·æŸ¥è¯¢ï¼‰

- `/query` API ç«¯ç‚¹
- `/query/stream` API ç«¯ç‚¹
- `/query/data` API ç«¯ç‚¹

### âœ… ä»¥ä¸‹åœºæ™¯è‡ªåŠ¨è®¾ç½® `is_user_query=False`ï¼ˆå†…éƒ¨è°ƒç”¨ï¼‰

- æ’å…¥æ–‡æ¡£ï¼š`await rag.ainsert(...)`
- å®ä½“æå–ï¼ˆçŸ¥è¯†åº“æ„å»ºè¿‡ç¨‹ï¼‰
- å…³ç³»æŠ½å–ï¼ˆçŸ¥è¯†åº“æ„å»ºè¿‡ç¨‹ï¼‰
- æ‘˜è¦ç”Ÿæˆï¼ˆçŸ¥è¯†åº“æ„å»ºè¿‡ç¨‹ï¼‰
- ç¨‹åºå†…ç›´æ¥è°ƒç”¨ï¼š`await rag.aquery(...)`ï¼ˆä¸é€šè¿‡ APIï¼‰

---

## ğŸ”§ åç«¯æœåŠ¡å™¨é…ç½®

### æ–¹æ¡ˆ 1: Nginx åå‘ä»£ç†

åœ¨ä½ çš„ Nginx é…ç½®ä¸­ï¼š

```nginx
server {
    listen 8000;
    
    location /v1/chat/completions {
        # æ ¹æ® Header è½¬å‘åˆ°ä¸åŒçš„åç«¯
        if ($http_x_user_query = "true") {
            proxy_pass http://aliyun-qwen.com:8000;  # ç”¨æˆ·æŸ¥è¯¢ â†’ é˜¿é‡Œäº‘
        }
        
        if ($http_x_user_query = "false") {
            proxy_pass http://127.0.0.1:11434;       # å†…éƒ¨è°ƒç”¨ â†’ æœ¬åœ°
        }
    }
}
```

### æ–¹æ¡ˆ 2: è‡ªå®šä¹‰ç½‘å…³

å¦‚æœä½ æœ‰è‡ªå·±çš„ç½‘å…³æœåŠ¡ï¼š

```python
# åœ¨ä½ çš„ç½‘å…³ä¸­æ£€æŸ¥ Header
def route_llm_request(request):
    is_user_query = request.headers.get("X-User-Query", "false")
    
    if is_user_query == "true":
        # ç”¨æˆ·æŸ¥è¯¢ â†’ é˜¿é‡Œäº‘ Qwen
        return forward_to("https://aliyun-qwen-api.com/v1/chat/completions")
    else:
        # å†…éƒ¨è°ƒç”¨ â†’ æœ¬åœ° Qwen
        return forward_to("http://localhost:11434/v1/chat/completions")
```

---

## ğŸ“‹ å®Œæ•´ç¤ºä¾‹

### ç¯å¢ƒå˜é‡é…ç½®ï¼ˆ.envï¼‰

```bash
# å¤§æ¨¡å‹æœåŠ¡å™¨åœ°å€ï¼ˆåŒä¸€ä¸ªåœ°å€ï¼Œåç«¯é€šè¿‡ Header è·¯ç”±ï¼‰
LLM_BINDING_HOST=http://your-gateway:8000/v1

# å¤§æ¨¡å‹é…ç½®
LLM_MODEL=qwen-plus
OPENAI_API_KEY=your-api-key

# Embedding é…ç½®
EMBEDDING_MODEL=bge-m3:latest
EMBEDDING_BINDING_HOST=http://localhost:11434
EMBEDDING_DIM=1024
```

### Python ä»£ç 

```python
import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import openai_complete_if_cache
from lightrag.utils import EmbeddingFunc

# LLM å‡½æ•°ï¼ˆå¸¦ Header æ”¯æŒï¼‰
async def llm_with_header(prompt, system_prompt=None, 
                         history_messages=[], is_user_query=False, **kwargs):
    client_configs = kwargs.pop("openai_client_configs", {})
    default_headers = client_configs.get("default_headers", {})
    
    # æ·»åŠ è‡ªå®šä¹‰ Header
    default_headers["X-User-Query"] = "true" if is_user_query else "false"
    client_configs["default_headers"] = default_headers
    
    return await openai_complete_if_cache(
        model=os.getenv("LLM_MODEL"),
        prompt=prompt,
        system_prompt=system_prompt,
        history_messages=history_messages,
        api_key=os.getenv("OPENAI_API_KEY"),
        base_url=os.getenv("LLM_BINDING_HOST"),
        openai_client_configs=client_configs,
        **kwargs,
    )

# åˆå§‹åŒ– RAG
async def main():
    rag = LightRAG(
        working_dir="./rag_storage",
        llm_model_func=llm_with_header,
        embedding_func=EmbeddingFunc(...),
    )
    
    await rag.initialize_storages()
    
    # åœºæ™¯ 1: æ’å…¥æ–‡æ¡£ï¼ˆè‡ªåŠ¨ç”¨æœ¬åœ° Qwenï¼‰
    await rag.ainsert("AI æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯...")
    
    # åœºæ™¯ 2: ç”¨æˆ·æŸ¥è¯¢ï¼ˆé€šè¿‡ API ä¼šè‡ªåŠ¨ç”¨é˜¿é‡Œäº‘ Qwenï¼‰
    # å¦‚æœç›´æ¥è°ƒç”¨éœ€è¦æ‰‹åŠ¨è®¾ç½®
    result = await rag.aquery("ä»€ä¹ˆæ˜¯ AIï¼Ÿ", 
                              param=QueryParam(mode="mix", is_user_query=True))
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ§ª æµ‹è¯•éªŒè¯

è¿è¡Œå®˜æ–¹ç¤ºä¾‹ï¼š

```bash
python examples/lightrag_user_query_header_demo.py
```

ä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š

```
åœºæ™¯ 1: æ’å…¥æ–‡æ¡£ï¼ˆå†…éƒ¨è°ƒç”¨ - çŸ¥è¯†åº“æ„å»ºï¼‰
--------------------------------------------------------------------------------
[DEBUG] ğŸŸ¢ å†…éƒ¨è°ƒç”¨ - æ·»åŠ  Header: X-User-Query: false
âœ“ æ–‡æ¡£æ’å…¥å®Œæˆ

åœºæ™¯ 2: ç”¨æˆ·æŸ¥è¯¢ï¼ˆAPI è°ƒç”¨ - æ¨¡æ‹Ÿç”¨æˆ·è¯·æ±‚ï¼‰
--------------------------------------------------------------------------------
[DEBUG] ğŸ”µ ç”¨æˆ·æŸ¥è¯¢ - æ·»åŠ  Header: X-User-Query: true
æŸ¥è¯¢ç»“æœé¢„è§ˆ: ...
```

---

## ğŸ“– æ›´å¤šæ–‡æ¡£

- ğŸ“˜ [è¯¦ç»†é…ç½®æŒ‡å—](./UserQueryHeaderConfiguration.md)
- ğŸ“™ [å®ç°æŠ€æœ¯æ–‡æ¡£](./PATCH_SUMMARY.md)
- ğŸ“— [å®Œæ•´ç¤ºä¾‹ä»£ç ](../examples/lightrag_user_query_header_demo.py)

---

## â“ å¸¸è§é—®é¢˜

**Q: æˆ‘ä¸€å®šè¦ç”¨ä¸¤ä¸ªä¸åŒçš„ Qwen å—ï¼Ÿ**  
A: ä¸ä¸€å®šã€‚ä½ å¯ä»¥ç”¨äºè®¡è´¹ç»Ÿè®¡ã€ç›‘æ§ã€è´Ÿè½½å‡è¡¡ç­‰ä»»ä½•éœ€è¦åŒºåˆ†è¯·æ±‚ç±»å‹çš„åœºæ™¯ã€‚

**Q: ä¼šå½±å“æ€§èƒ½å—ï¼Ÿ**  
A: ä¸ä¼šã€‚åªæ˜¯åœ¨ HTTP Header ä¸­å¤šåŠ äº†ä¸€ä¸ªå­—æ®µï¼Œå¼€é”€å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚

**Q: å¦‚ä½•è°ƒè¯• Header æ˜¯å¦æ­£ç¡®ï¼Ÿ**  
A: åœ¨ LLM å‡½æ•°ä¸­æ·»åŠ  `print(f"Headers: {default_headers}")`ï¼Œæˆ–ä½¿ç”¨æŠ“åŒ…å·¥å…·ã€‚

**Q: å…¼å®¹æ—§ä»£ç å—ï¼Ÿ**  
A: å®Œå…¨å…¼å®¹ï¼ä¸è®¾ç½® `is_user_query` æ—¶é»˜è®¤ä¸º `False`ï¼Œæ—§ä»£ç æ— éœ€ä¿®æ”¹ã€‚

---

## ğŸ‰ å¼€å§‹ä½¿ç”¨

1. **ä¿®æ”¹ LLM å‡½æ•°**ï¼ˆæ·»åŠ  Header å¤„ç†ï¼‰
2. **é…ç½®åç«¯è·¯ç”±**ï¼ˆNginx æˆ–è‡ªå®šä¹‰ç½‘å…³ï¼‰
3. **è¿è¡Œæµ‹è¯•**ï¼ˆéªŒè¯ Header æ­£ç¡®å‘é€ï¼‰
4. **éƒ¨ç½²ä¸Šçº¿**

å°±è¿™ä¹ˆç®€å•ï¼ğŸš€
